# Projects

Here are the key projects we're working on to enhance Medispeak's capabilities. We welcome contributions and discussions on these initiatives!

## Support for Open Source AI Models
- Integration with various open-source AI models for transcription and understanding
- Support for local model deployment
- Customizable model training for specific medical specialties
- Performance optimization for different hardware configurations

## Self Hosted Whisper Support
- Local deployment of Whisper models
- Custom model fine-tuning capabilities
- Offline transcription support
- Resource usage optimization
- Docker container support

## Multiple Recording Support
- Simultaneous recording from multiple sources
- Support for different audio input devices
- Session management for multiple recordings
- Batch processing capabilities
- Audio quality optimization

## UI Based Setup of New Pages
- Drag-and-drop interface for page creation
- Template management system
- Custom field mapping interface
- Real-time preview capabilities
- Export/import configuration

## Smart Navigation of EMR
- Voice-controlled EMR navigation
- Context-aware command interpretation
- Customizable navigation shortcuts
- Smart field detection
- Adaptive learning from user patterns

## Live Transcription with Whisper
- Real-time audio streaming to Whisper
- Low-latency transcription
- Continuous transcription mode
- Automatic punctuation and formatting
- Error correction on the fly

## Getting Involved

If you're interested in contributing to any of these projects:
1. Check our [Contributing Guidelines](/docs/contribute)
2. Join the discussion in our [GitHub Discussions](https://github.com/medispeak/discussions)
3. Pick a project that interests you
4. Start with our development setup guide

We prioritize contributions based on:
- Community needs
- Technical feasibility
- Impact on user experience
- Available resources

Your contributions can help make healthcare documentation more efficient and accessible for everyone! 